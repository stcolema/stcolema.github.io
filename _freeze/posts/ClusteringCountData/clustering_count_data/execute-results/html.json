{
  "hash": "ad39f26326d8d36ebaf3fac315d8d498",
  "result": {
    "markdown": "---\ntitle: \"Clustering count data\"\neditor: visual\ndata: 2022-06-01\ncategories: [Clustering]\n---\n\n\nThis vignette explores clustering count data and the impact of some data transforms on this.\n\nWe will consider a $\\log$-transform and the mean-centring and scaling (i.e., standardisation). For a vector of data $X$, these are:\n\n\\begin{align}\n\\text{Log-transform: } X \\to \\log(1 + X), \\\\\n\\text{Standardisation: } X \\to \\frac{X - \\bar{X}}{\\bar{\\sigma}},\n\\end{align}\n\nwhere $\\bar{X}$ is the empirical mean of $X$, and $\\bar{\\sigma}$ is the empirical standard deviation.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Call libraries\n\n# For mixture models\nlibrary(mclust)\nlibrary(mixtools)\nlibrary(mdir)\n\n# For visualisation\nlibrary(pheatmap)\nlibrary(ggplot2)\n\n# For ``gather`` function\nlibrary(tidyr)\n\n# For the pipe and some extensions\nlibrary(magrittr)\n\n# Set seed for reproducibility\nset.seed(1)\ncol_pal <- (grDevices::colorRampPalette(c(\"#146EB4\", \"white\", \"#FF9900\")))(100)\n\nggplot2::theme_set(\n  ggplot2::theme_bw()\n  + ggplot2::theme(strip.background = ggplot2::element_rect(fill = \"#21677e\"))\n    + ggplot2::theme(strip.text = ggplot2::element_text(colour = \"white\"))\n)\n```\n:::\n\n\n## Generate count data\n\nFirst we create 5 subpopulations with some peturbation about a mean.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Example of transforms on poission data\nn <- 100\nbeta_0 <- c(1, 1, 5, 6, 2, 2)\nbeta_1 <- c(0.2, 0.2, 1, 2.5, 2, 2)\n\n# Generate random data\nx <- runif(n = n, min = 0, max = 2.0)\n\n# Generate data from 4 poisson regression models\nbeta_1_mat <- sapply(beta_1, `*`, x)\nexponent_mat <- t(apply(beta_1_mat, 1, `+`, t(beta_0)))\n\npoisson_data <- apply(exp(exponent_mat), 2, function(x) {\n  rpois(n = n, lambda = x)\n})\n\n# Put this data into a data.frame\npoisson_df <- data.frame(\n  Count_1 = c(poisson_data[, 1], poisson_data[, 3]),\n  Count_2 = c(poisson_data[, 2], poisson_data[, 4]),\n  Count_3 = c(poisson_data[, 5], poisson_data[, 6])\n)\n```\n:::\n\n\nCreate some data that follows a sigmoidal curve:\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# some continuous variables\nx1 <- runif(2 * n, -2, -1)\nx2 <- runif(2 * n, 1, 2)\nx3 <- runif(2 * n, -1, 1)\n\n# linear combination with a bias\nz <- 1 + 8 * x1 + 7.5 * x2 + 5 * x3\n\n# pass through an inverse logit function and move to a scale similar to a count\npr <- round(1 / (1 + exp(-z)) * 1000)\n\nplot(z, pr, main = \"Discere sigmoidal data\")\n```\n\n::: {.cell-output-display}\n![](clustering_count_data_files/figure-html/gen_sigmoid_data-1.png){width=672}\n:::\n\n```{.r .cell-code}\nhist(pr, main = \"Discere sigmoidal data\")\n```\n\n::: {.cell-output-display}\n![](clustering_count_data_files/figure-html/gen_sigmoid_data-2.png){width=672}\n:::\n:::\n\n\nWe add a feature generated from a different model; this follows a sigmoidal curve. We combine this with our previously generated data.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Arbitrary step to have the high counts align in each dataset imperfectly but well\n# enough to have less sub-populations emerge from the combined dataset\nfractions <- 8\nnew_order <- order(pr)\nflag <- as.numeric(cut(pr,\n  breaks = quantile(pr, probs = seq(0, 1, 1 / fractions)),\n  include.lowest = T,\n  labels = 1:fractions\n))\n\nflag[flag %in% 3:4] <- fractions + 1\n\n# Combine the generated data\nmy_data <- as.data.frame(cbind(poisson_df, pr[order(flag)]))\n\n# Assign row and column names\ncolnames(my_data) <- c(paste0(\"Count_\", 1:(ncol(poisson_df) + 1)))\nrow.names(my_data) <- paste(\"Person_\", 1:nrow(my_data))\n\n# Of some use later\nn_var <- ncol(my_data)\n\nhead(my_data)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n          Count_1 Count_2 Count_3 Count_4\nPerson_ 1       4       2      18       0\nPerson_ 2       2       2      30       3\nPerson_ 3       2       3      89      11\nPerson_ 4       9       3     269       0\nPerson_ 5       3       1      23       2\nPerson_ 6       2       4     238       0\n```\n:::\n:::\n\n\nNow we apply our transforms.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Log transform\nlog_data <- log(1 + my_data) %>% as.data.frame()\n\n# Mean centre and standardise the standard deviation within each variable\nscaled_data <- apply(my_data, 2, scale) %>%\n  as.data.frame() |>\n  set_rownames(row.names(my_data))\n\n# Let's now try combining these two\nscaled_log_data <- apply(log(1 + my_data), 2, scale) %>%\n  as.data.frame() |>\n  set_rownames(row.names(my_data))\n```\n:::\n\n\nLet us look at the distributions described by each variable for each dataset. We expect there to be two subpopulations present under variables \"Count_1\", \"Count_2\" and \"Count_4\", and a single population under \"Count_3\".\n\n\n::: {.cell}\n\n```{.r .cell-code}\nggplot(gather(my_data), aes(value)) +\n  geom_histogram() +\n  facet_wrap(~key, scales = \"free_x\") +\n  labs(\n    title = \"Distribution of original data\",\n    x = \"Count\",\n    y = \"Frequency\"\n  )\n```\n\n::: {.cell-output .cell-output-stderr}\n```\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n```\n:::\n\n::: {.cell-output-display}\n![](clustering_count_data_files/figure-html/visualise_data-1.png){width=672}\n:::\n\n```{.r .cell-code}\npheatmap(my_data,\n  color = col_pal,\n  main = \"Generated data\",\n  show_rownames = FALSE,\n  cluster_cols = FALSE\n)\n```\n\n::: {.cell-output-display}\n![](clustering_count_data_files/figure-html/visualise_data-2.png){width=672}\n:::\n\n```{.r .cell-code}\nggplot(gather(log_data), aes(value)) +\n  geom_histogram() +\n  facet_wrap(~key, scales = \"free_x\") +\n  labs(\n    title = \"Distribution of log-transformed data\",\n    x = \"Count\",\n    y = \"Frequency\"\n  )\n```\n\n::: {.cell-output .cell-output-stderr}\n```\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n```\n:::\n\n::: {.cell-output-display}\n![](clustering_count_data_files/figure-html/visualise_data-3.png){width=672}\n:::\n\n```{.r .cell-code}\npheatmap(log_data,\n  color = col_pal,\n  main = \"Log-transformed data\",\n  show_rownames = FALSE,\n  cluster_cols = FALSE\n)\n```\n\n::: {.cell-output-display}\n![](clustering_count_data_files/figure-html/visualise_data-4.png){width=672}\n:::\n\n```{.r .cell-code}\nggplot(gather(scaled_data), aes(value)) +\n  geom_histogram() +\n  facet_wrap(~key, scales = \"free_x\") +\n  labs(\n    title = \"Distribution of standardised data\",\n    x = \"Count\",\n    y = \"Frequency\"\n  )\n```\n\n::: {.cell-output .cell-output-stderr}\n```\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n```\n:::\n\n::: {.cell-output-display}\n![](clustering_count_data_files/figure-html/visualise_data-5.png){width=672}\n:::\n\n```{.r .cell-code}\npheatmap(scaled_data,\n  color = col_pal,\n  main = \"Standardised data\",\n  show_rownames = FALSE,\n  cluster_cols = FALSE\n)\n```\n\n::: {.cell-output-display}\n![](clustering_count_data_files/figure-html/visualise_data-6.png){width=672}\n:::\n\n```{.r .cell-code}\nggplot(gather(scaled_log_data), aes(value)) +\n  geom_histogram() +\n  facet_wrap(~key, scales = \"free_x\") +\n  labs(\n    title = \"Distribution of standardised log-transformed data\",\n    x = \"Count\",\n    y = \"Frequency\"\n  )\n```\n\n::: {.cell-output .cell-output-stderr}\n```\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n```\n:::\n\n::: {.cell-output-display}\n![](clustering_count_data_files/figure-html/visualise_data-7.png){width=672}\n:::\n\n```{.r .cell-code}\npheatmap(scaled_log_data,\n  color = col_pal,\n  main = \"Standardised log-transformed data\",\n  show_rownames = FALSE,\n  cluster_cols = FALSE\n)\n```\n\n::: {.cell-output-display}\n![](clustering_count_data_files/figure-html/visualise_data-8.png){width=672}\n:::\n:::\n\n\nNote that standardising has not impacted how well-separated the groups in the data are, it has merely changed the scale and location of the data.\n\nIn terms of separating out the subpopulations, it appears that the $\\log$-transform has worked most effectively for the first two variables, but does not succeed with the sigmoidal data. This reminds us that a single transform might not be appropriate for an entire dataset; however, many datasets are too large to check each feature manually, this is simply to make the point that we often lose some signal and minimising this is only so feasible.\n\nWe will now attempt to infer the latent clustering labels using mixture models. I use the ``Mclust`` function from the ``mclust`` package and the ``mvnormalmixEM`` from ``mixtools`` to create Gaussian mixture models. We will look at the clustering predicted for the data using ``pheatmap``. \n\nI create some labels for the sigmoidal data to keep track of the tails - we hope these are allocated correctly and are probably the hardest sub-populations to untangle for the $\\log$-transformed data. These labels are based on which tertiles the sigmoidal data falls into and is intended as a rough guide of how well the models deconstruct the sigmoidal data.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Keep track of the sigmoidal data by assigning a label based on quantiles\nn_labels <- 3\nsig_labels <- cut(my_data[, n_var],\n  breaks = quantile(my_data[, n_var], probs = seq(0, 1, 1 / n_labels)),\n  include.lowest = T,\n  labels = 1:n_labels\n)\n\n# Create a data.frame to annotate the heatmaps\nannotation_row <- data.frame(Sig_pop = as.factor(sig_labels))\nrow.names(annotation_row) <- row.names(my_data)\n```\n:::\n\n\n## Model fitting\n\nNow attempt to fit models. I find that ``mixtools`` is less robust to ``mclust`` (struggles to solve the same datasets, even with the `hclust` initialisation). For this reason I comment out the code for fitting the `mixtools` model.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmodel_functions <- c(\n  \"Mclust\",\n  \"mvnormalmixEM\"\n)\n\ntransforms <- c(\n  \"Original\",\n  \"Log\",\n  \"Standardise\"\n)\n\ndatasets <- list(my_data, log_data, scaled_data) %>%\n  set_names(transforms)\n\nn_datasets <- length(datasets)\nn_models <- length(model_functions)\n\nmodel_out <- vector(\"list\", n_models) %>%\n  set_names(model_functions)\n\nmodel_bic <- model_out\n\nfor (i in 1:n_models) {\n  model_out[[i]] <- vector(\"list\", n_datasets) %>%\n    set_names(transforms)\n\n  model_bic[[i]] <- model_out[[i]]\n\n  if (model_functions[i] == \"Mclust\") {\n    for (j in 1:n_datasets) {\n      # do.call(model_functions[i], list(datasets[[j]])\n      model_out[[i]][[j]] <- Mclust(datasets[[j]], G = 2:15)\n      model_bic[[i]][[j]] <- mclustBIC(datasets[[j]])\n    }\n  }\n  # if (model_functions[i] == \"mvnormalmixEM\") {\n  #   for (j in 1:n_datasets) {\n  #     for(k in seq(2, 15)) {\n  #       initial_clusterings <- datasets[[j]] |>\n  #         dist() |>\n  #         hclust() |>\n  #         cutree(k = k)\n  #       initial_means <- vector(\"list\", k)\n  #       for(l in seq(1, k)) {\n  #         cluster_inds <- which(initial_clusterings == l)\n  #         initial_means[[l]] <- colMeans(datasets[[j]][cluster_inds, ])\n  #       }\n  #\n  #       model_out[[i]][[j]] <- mvnormalmixEM(datasets[[j]], k = k, mu = initial_means)\n  #     }\n  #   }\n  # }\n}\n```\n:::\n\n\nWe can now inspect the model using several different visualisations. We can investigate the optimal number of components under the Bayesian Information Criterion (BIC) and we can look at the clusterings as defined by pairs of variables. I will look at the models defined on the scaled data and the ``log``-transformed data. The BIC vs $k$ plot also shows which of the possible types of covariance structure allowed by ``Mclust`` is optimal (this is the difference models listed and plotted).\n\n\n::: {.cell}\n\n```{.r .cell-code}\nsummary(model_out[[1]][[2]])\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n---------------------------------------------------- \nGaussian finite mixture model fitted by EM algorithm \n---------------------------------------------------- \n\nMclust VVE (ellipsoidal, equal orientation) model with 8 components: \n\n log-likelihood   n df       BIC       ICL\n      -456.7326 200 77 -1321.436 -1331.303\n\nClustering table:\n 1  2  3  4  5  6  7  8 \n21 29 30 20 49 17  7 27 \n```\n:::\n\n```{.r .cell-code}\nplot(model_out[[1]][[2]], what = \"classification\")\n```\n\n::: {.cell-output-display}\n![](clustering_count_data_files/figure-html/inspect_models-1.png){width=672}\n:::\n\n```{.r .cell-code}\nplot(model_out[[1]][[2]], what = \"BIC\")\n```\n\n::: {.cell-output-display}\n![](clustering_count_data_files/figure-html/inspect_models-2.png){width=672}\n:::\n\n```{.r .cell-code}\nsummary(model_out[[1]][[3]])\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n---------------------------------------------------- \nGaussian finite mixture model fitted by EM algorithm \n---------------------------------------------------- \n\nMclust VVV (ellipsoidal, varying volume, shape, and orientation) model with 8\ncomponents: \n\n log-likelihood   n  df      BIC      ICL\n       990.4389 200 119 1350.378 1344.508\n\nClustering table:\n 1  2  3  4  5  6  7  8 \n20 30 25 25 23 24 23 30 \n```\n:::\n\n```{.r .cell-code}\nplot(model_out[[1]][[3]], what = \"classification\")\n```\n\n::: {.cell-output-display}\n![](clustering_count_data_files/figure-html/inspect_models-3.png){width=672}\n:::\n\n```{.r .cell-code}\nplot(model_out[[1]][[3]], what = \"BIC\")\n```\n\n::: {.cell-output-display}\n![](clustering_count_data_files/figure-html/inspect_models-4.png){width=672}\n:::\n:::\n\n\nWe can see that by using a vector of possible components (the input ``G = 2:15`` in the call to ``Mclust``), we have captured the optimal value. This is the global maximum in the plot comparing BIC to number of components for each model allowed by ``Mclust``. One thing to notice here is that the two models do agree on the optimal number of components (8), but that this is not expected to occurr, particularly for datasets of greater dimension. Another point is that the type of model that best fits the scaled data is the \"EVE\" model in comparison to the \"VVV\" model. This is a simpler model where each cluster has more restrictions on its parameters - thus the EVE model is easier to run (this is worth remembering if ``log``-transformed data demands to complex a model computationally). \n\nIn the plots comparing clusterings across variables, we can see that the model defined on the ``log``-transformed data separates the two sub-populations in $Count_1$ and $Count_2$ with much greater confidence than the model defined on the standardised data. One can also see that $Count_3$, which has no sub-population structure, is not contributing significantly to the cluster allocaitons - the data is pretty uniformly distributed across the axis defined by $Count_3$, no clear partitions emerging. One can see that the sigmoidal structure in $Count_4$ is captured quie well by the ``log`` model.\n\n## Results \n\nLet us now inspect the clustering inferred I ignore the original data as the scaling makes inspecting the data unfeasible.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlabelling <- lapply(model_out$Mclust, function(x) {\n  x$classification\n}) |>\n  as.data.frame() |>\n  set_rownames(row.names(my_data))\n\nannotation_row <- labelling\n\npheatmap(log_data[order(annotation_row[, 1]), ],\n  cluster_rows = F,\n  cluster_cols = F,\n  annotation_row = annotation_row,\n  main = \"Log-transformed data:\\nOrdered by clustering of original data\"\n)\n```\n\n::: {.cell-output-display}\n![](clustering_count_data_files/figure-html/visualise_results-1.png){width=672}\n:::\n\n```{.r .cell-code}\npheatmap(log_data[order(annotation_row[, 2]), ],\n  cluster_rows = F,\n  cluster_cols = F,\n  annotation_row = annotation_row,\n  main = \"Log-transformed data:\\nOrdered by clustering of log-transformed data\"\n)\n```\n\n::: {.cell-output-display}\n![](clustering_count_data_files/figure-html/visualise_results-2.png){width=672}\n:::\n\n```{.r .cell-code}\npheatmap(log_data[order(annotation_row[, 3]), ],\n  cluster_rows = F,\n  cluster_cols = F,\n  annotation_row = annotation_row,\n  main = \"Log-transformed data:\\nOrdered by clustering of scaled data\"\n)\n```\n\n::: {.cell-output-display}\n![](clustering_count_data_files/figure-html/visualise_results-3.png){width=672}\n:::\n\n```{.r .cell-code}\npheatmap(scaled_data[order(annotation_row[, 1]), ],\n  cluster_rows = F,\n  cluster_cols = F,\n  annotation_row = annotation_row,\n  main = \"Standardised data:\\nOrdered by clustering of original data\"\n)\n```\n\n::: {.cell-output-display}\n![](clustering_count_data_files/figure-html/visualise_results-4.png){width=672}\n:::\n\n```{.r .cell-code}\npheatmap(scaled_data[order(annotation_row[, 2]), ],\n  cluster_rows = F,\n  cluster_cols = F,\n  annotation_row = annotation_row,\n  main = \"Standardised data:\\nOrdered by clustering of log-transformed data\"\n)\n```\n\n::: {.cell-output-display}\n![](clustering_count_data_files/figure-html/visualise_results-5.png){width=672}\n:::\n\n```{.r .cell-code}\npheatmap(scaled_data[order(annotation_row[, 3]), ],\n  cluster_rows = F,\n  cluster_cols = F,\n  annotation_row = annotation_row,\n  main = \"Standardised data:\\nOrdered by clustering of scaled data\"\n)\n```\n\n::: {.cell-output-display}\n![](clustering_count_data_files/figure-html/visualise_results-6.png){width=672}\n:::\n:::\n\n\nWe comapre the similarity of the inferred clusterings using the Adjusted Rand Index. This scores clustering similarities, with 0 meaning the two partitions are no more similar then a random pair of clusterings is expected to be and 1 meaning they are identical.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nari_12 <- mcclust::arandi(annotation_row[, 1], annotation_row[, 2])\nari_13 <- mcclust::arandi(annotation_row[, 1], annotation_row[, 3])\nari_23 <- mcclust::arandi(annotation_row[, 2], annotation_row[, 3])\n\nari_mat <- matrix(c(1.0, ari_12, ari_13, ari_12, 1.0, ari_23, ari_13, ari_23, 1.0),\n  nrow = 3,\n  ncol = 3\n) |> \n  set_colnames(c(\"Original\", \"Log-transformed\", \"Standardised\")) |> \n  set_rownames(c(\"Original\", \"Log-transformed\", \"Standardised\"))\n\nknitr::kable(ari_mat, digits = 3)\n```\n\n::: {.cell-output-display}\n|                | Original| Log-transformed| Standardised|\n|:---------------|--------:|---------------:|------------:|\n|Original        |    1.000|           0.702|        1.000|\n|Log-transformed |    0.702|           1.000|        0.702|\n|Standardised    |    1.000|           0.702|        1.000|\n:::\n:::\n\n\n## Summary\n\nWe see that from the Gaussian mixture models perspective the original and standardised are interchangeable, leading to identical inference. Both datasets lead to a surprisingly similar clustering to the log-transformed  data; 0.7 is not a low ARI. Furthermore, we can see in the annotated heatmaps that a large source of the contention is that one cluster found in the log-transformed data is considered as two separate groups in the original (cluster 6 in the log-transformed inference approximately captures clusters 6 and 5 from the other point estimates), and conversely cluster 8 in the original data splits into two clusters in the log-transformed data. Deciding which of these is more useful, or if we should use 7 or 9 clusters rather then 8 involves further thought and ideally conversation with a domain expert.\n\n",
    "supporting": [
      "clustering_count_data_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}