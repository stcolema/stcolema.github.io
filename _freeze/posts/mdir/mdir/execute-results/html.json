{
  "hash": "4abf516de97a419b81a554a772d3e4a2",
  "result": {
    "markdown": "---\ntitle: \"mdir: Bayesian multi-omics clustering\"\neditor: visual\ndata: 2023-03-01\ncategories: [Bayes]\n---\n\n\nThis vignette introduces the `mdir` R package. This package offers software for Bayesian model based clustering and the Multiple Dataset Integration model for multi-omics analysis. It uses the C++17 parallel policies and thus is unavailable on MAC OS and Debian systems when used with the default C++ compilers.\n\n# Model\n\nMultiple Dataset Integration (**MDI**), is a multi-omics method proposed by Kirk et. al (2012) that extends the Bayesian mixture model to jointly model $M$ datasets. We introduce the mixture model and then MDI before outlining how to use the `mdir` package.\n\n## Mixture models\n\nLet $X=(X_1, \\ldots, X_N)$ be the observed data, with $X_n = [X_{n, 1}, \\ldots, X_{n,P}]^\\top$ for each item being considered, where each observation has $P$ variables. We wish to model the data using a mixture of densities:\n\\begin{align}\n\tp(X_n | \\theta = \\{\\theta_1, \\ldots, \\theta_K\\}, \\pi) &= \\sum_{k=1}^K \\pi_k f(X_n | \\theta_k)\n\\end{align}\nindependently for each $n = 1, \\ldots, N$. Here, $f(\\cdot)$ is a probability density function such as the Gaussian density function or the categorical density function, and each component has its own weight, $\\pi_k$, and set of parameters, $\\theta_k$. The component weights are restricted to the unit simplex, i.e., $\\sum_{k=1}^K \\pi_k = 1$. To capture the discrete structure in the data, we introduce an allocation variable, $c=[c_1, \\ldots, c_N]^\\top, c_n \\in [1, K] \\subset \\mathbb{N}$, to indicate which component a sample was drawn from, introducing conditional independence between the components,\n\\begin{align}\n\tp(c_n = k) &= \\pi_k, \\\\\n\tp(X_n | c_n = k, \\theta_k) &= f(X_n | \\theta_k).\n\\end{align}\nThe joint model can then be written\n\\begin{align}\n\tp(X, c, K, \\pi, \\theta) &= p(X | c, \\pi, K, \\theta) p(\\theta | c, \\pi, K) p(c | \\pi, K) p(\\pi | K) p(K).\n\\end{align}\nWe assume conditional independence between certain parameters such that the model reduces to\n\\begin{align}\n\tp(X, c, \\theta, \\pi, K) &=  p(\\pi | K) p(\\theta | K) p(K) \\prod_{n=1}^N p(X_n | c_n, \\theta_{c_n}) p (c_n | \\pi).  \\label{eqn:jointMixModel}\n\\end{align}\nIn terms of the hierarchical model this is:\n\\begin{align}\n    X_n | c_n, \\theta &\\sim F(\\theta_{c_n}), \\\\\n    c_n | \\pi &\\sim \\text{Multinomial}(\\pi_1, \\ldots, \\pi_K), \\\\\n    \\pi_1, \\ldots, \\pi_K &\\sim \\text{Dirichlet}(\\alpha / K, \\ldots, \\alpha / K), \\\\\n    \\theta_k &\\sim G^{(0)},\n\\end{align}\nwhere $F$ is the appropriate distribution (e.g., Gaussian, Categorical, etc.) and $G^{(0)}$ is some prior over the component parameters.\n\n## MDI\n\nMDI is a Bayesian integrative or multi-modal clustering method.  Signal sharing is defined by the prior on the cluster label of the $n^{th}$ observation in the $M$ modalities:\n\\begin{align}\np(c_n^{(1)}, \\ldots, c_n^{(M)} | \\cdot) &= \\prod_{m=1}^M \\gamma^{(m)}_{c_n^{(m)}} \\prod_{m = 1}^{M-1} \\prod_{l = m + 1}^M (1 + \\phi_{(m, l)} \\mathbb{I} (c_n^{(m)} = c_n^{(l)})),\n \\end{align}\nwhere $c_n^{(m)}$ is the label of the $n^{th}$ observation in the $m^{th}$ modality, $\\gamma^{(m)}_{k}$ is the weight of the $k^{th}$ cluster in the $m^{th}$ modality, $\\phi_{(m, l)}$ is the similarity between the clusterings of the $m^{th}$ and $l^{th}$ modalities and $\\mathbb{I}(x)$ is the indicator function returning 1 if $x$ is true and 0 otherwise. Attractively, $\\phi_{(m, l)}$ is inferred from the data and if there is no shared signal it will tend towards 0 giving us no dependency between these modalities. Thus each dataset will have independent clusters.\n\n<!-- We use an overfitted mixture model \\cite{rousseau2011asymptotic} to approximate a Dirichlet process mixture model \\cite{ferguson1973bayesian, AntoniakMixturesDirichletProcesses1974, FergusonBayesianDensityEstimation1983, LoClassBayesianNonparametric1984} in each unsupervised modality, allowing inference of the number of clusters/classes present. If a number of classes are observed but one believes that additional classes might be present in the data one may use a semi-supervised overfitted mixture to detect novel classes as per Crook et al. \\cite{Crook2020NoveltyDetection}. -->\n\n# Data generation\n\nTo showcase the MDI method, we generate three datasets with correlated clustering structures. To do this we load the appropriate packages and write some functions to ensure our data do have related generating structure.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(mdir)\nlibrary(mdiHelpR)\n```\n\n::: {.cell-output .cell-output-stderr}\n```\n\nAttaching package: 'mdiHelpR'\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\nThe following objects are masked from 'package:mdir':\n\n    createSimilarityMat, findOrder, generateGaussianDataset,\n    generateSimulationDataset, runMDI\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\nThe following object is masked from 'package:methods':\n\n    show\n```\n:::\n\n```{.r .cell-code}\nlibrary(batchmix)\n```\n\n::: {.cell-output .cell-output-stderr}\n```\n\nAttaching package: 'batchmix'\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\nThe following object is masked from 'package:mdiHelpR':\n\n    createSimilarityMat\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\nThe following objects are masked from 'package:mdir':\n\n    calcAllocProb, createSimilarityMat, gammaLogLikelihood,\n    generateInitialLabels, getLikelihood, invGammaLogLikelihood,\n    invWishartLogLikelihood, plotLikelihoods,\n    predictFromMultipleChains, processMCMCChain, processMCMCChains,\n    runMCMCChains, wishartLogLikelihood\n```\n:::\n\n```{.r .cell-code}\nlibrary(magrittr)\nlibrary(mcclust)\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nLoading required package: lpSolve\n```\n:::\n\n```{.r .cell-code}\nRcppParallel::setThreadOptions()\n\nsetMyTheme()\nset.seed(1)\n\ngenerateGaussianView <- function(cluster_means, std_devs, N, P, labels,\n                                 row_names = paste0(\"Person_\", 1:n),\n                                 col_names = paste0(\"Gene_\", 1:p)) {\n  gen_data <- matrix(0, N, P)\n\n  for (ii in seq(1, P)) {\n    reordered_cluster_means <- sample(cluster_means)\n    reordered_std_devs <- sample(std_devs)\n\n    # Draw n points from the K univariate Gaussians defined by the permuted means.\n    for (jj in seq(1, N)) {\n      .mu <- reordered_cluster_means[labels[jj]]\n      .sd <- reordered_std_devs[labels[jj]]\n\n      # print(labels[jj])\n      # print(.mu)\n      # print(.sd)\n\n      gen_data[jj, ii] <- rnorm(1,\n        mean = .mu,\n        sd = .sd\n      )\n    }\n  }\n  gen_data\n}\n\ngenerateCategoricalView <- function(probs, N, P, labels,\n                                    row_names = paste0(\"Person_\", 1:n),\n                                    col_names = paste0(\"Gene_\", 1:p)) {\n  gen_data <- matrix(0, N, P)\n\n  for (ii in seq(1, P)) {\n    reordered_probs <- sample(probs)\n\n    # Draw n points from the K univariate Gaussians defined by the permuted means.\n    for (jj in seq(1, N)) {\n      .p <- reordered_probs[labels[jj]]\n\n      gen_data[jj, ii] <- sample(c(0, 1), 1, prob = c(1 - .p, .p))\n    }\n  }\n  gen_data\n}\n\ngenerateViewGivenStructure <- function(generating_structure, frac_present, P, K, class_weights, type, params) {\n  N <- length(generating_structure)\n  labels_transferred <- sample(c(0, 1), N, replace = TRUE, prob = c(1 - frac_present, frac_present))\n  labels_transferred_ind <- which(labels_transferred == 1)\n  N_transferred <- sum(labels_transferred)\n  N_new <- N - N_transferred\n  identical_view <- N_new == N\n  K_ind <- seq(1, K)\n  labels <- rep(0, N)\n  labels[labels_transferred_ind] <- generating_structure[labels_transferred_ind]\n  if (!identical_view) {\n    new_labels <- sample(K_ind, N - N_transferred, replace = TRUE, prob = class_weights)\n    labels[-labels_transferred_ind] <- new_labels\n  }\n  gaussian <- type == \"G\"\n  categorical <- type == \"C\"\n\n  if (gaussian) {\n    means <- params$means\n    std_devs <- params$std_devs\n    gen_data <- generateGaussianView(means, std_devs, N, P, labels)\n  }\n  if (categorical) {\n    probs <- params$probs\n    gen_data <- generateCategoricalView(probs, N, P, labels)\n  }\n\n  row.names(gen_data) <- names(generating_structure)\n\n  list(\n    gen_data = gen_data,\n    labels = labels\n  )\n}\n```\n:::\n\n\nWe generate three datasets (sometimes called modalities or views) containing 250 individuals. Our first dataset is generated from 7 classes and contains 400 features. To complicate the matter, we use the data generation method from the `batchmix` package. This models batch noise and variance using (essentially) a mixture-of-mixtures. Thus our model is misspecified in this dataset, as we will use a Gaussian to describe each class rather then a mixture of multivariate t densities, which is the generating model.\n\nOur second and third datasets are smaller with 25 and 20 features respectively. They also contain more clusters, with 15 and 10 generating clusters compared to the 7 in the first dataset. These data will be modelled with no observed labels, i.e. they are unsupervised, whereas the first dataset has 20% of the labels observed and is semi-supervised within the MDI framework.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nN <- 250\nP <- 100\nK <- 7\nB <- 3\n\ngroup_means <- rnorm(K, sd = 1)\ngroup_sds <- rgamma(K, 4, 2)\ngroup_dfs <- c(4, 10, 20, 50, 10, 20, 20)\n\nbatch_shift <- rnorm(B, sd = 0.5)\nbatch_scale <- 1 + rgamma(B, 10, 20)\n\ngroup_weights <- c(0.3, 0.2, 0.1, rep(0.4 / 4, 4))\nbatch_weights <- c(0.4, 0.4, 0.2)\n\ngen_data <- generateBatchData(N, P,\n  group_means = group_means,\n  group_std_devs = group_sds,\n  batch_shift = batch_shift,\n  batch_scale = batch_scale,\n  group_weights = group_weights,\n  batch_weights = batch_weights,\n  group_dfs = group_dfs\n)\n\nnames(gen_data$group_IDs) <- row.names(gen_data$observed_data)\n\nfrac_present_2 <- 0.5\nP_2 <- 40\nK_2 <- 15\nclass_weights_2 <- rgamma(K_2, 10)\nclass_weights_2 <- class_weights_2 / sum(class_weights_2)\nparams_2 <- list(\n  means = rnorm(K_2, sd = 2),\n  std_devs = rgamma(K_2, 2, 2)\n)\n\ngen_view_2 <- generateViewGivenStructure(gen_data$group_IDs,\n  frac_present = frac_present_2,\n  P = P_2,\n  K = K_2,\n  type = \"G\",\n  class_weights = class_weights_2,\n  params = params_2\n)\n\nfrac_present_3 <- 0.4\nP_3 <- 20\nK_3 <- 10\nclass_weights_3 <- rgamma(K_3, 10, 10)\nclass_weights_3 <- class_weights_3 / sum(class_weights_3)\n# probs <- rbeta(K_3, 1, 1)\nparams_3 <- list(\n  means = rnorm(K_3, sd = 2.0),\n  std_devs = rgamma(K_3, 2, 2)\n)\n\ngen_view_3 <- generateViewGivenStructure(gen_data$group_IDs,\n  frac_present = frac_present_3,\n  P = P_3,\n  K = K_3,\n  type = \"G\",\n  class_weights = class_weights_3,\n  params = params_3\n)\n```\n:::\n\n\n# Data visualisation\n\nWe visualise the data annotated by the generating structure.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nannotatedHeatmap(gen_data$observed_data, gen_data$group_IDs,\n  show_rownames = FALSE,\n  main = \"Dataset 1 (semi-supervised)\"\n)\n```\n\n::: {.cell-output-display}\n![](mdir_files/figure-html/dataViz-1.png){width=672}\n:::\n\n```{.r .cell-code}\nannotatedHeatmap(gen_view_2$gen_data, gen_view_2$labels,\n  show_rownames = FALSE,\n  main = \"Dataset 2 (unsupervised)\"\n)\n```\n\n::: {.cell-output-display}\n![](mdir_files/figure-html/dataViz-2.png){width=672}\n:::\n\n```{.r .cell-code}\nannotatedHeatmap(gen_view_3$gen_data, gen_view_3$labels,\n  show_rownames = FALSE,\n  main = \"Dataset 3 (unsupervised)\"\n)\n```\n\n::: {.cell-output-display}\n![](mdir_files/figure-html/dataViz-3.png){width=672}\n:::\n:::\n\n\n# Model fitting\n\nWe run 5 chains of MDI for 15,000 iterations. In the second and third datasets we use an excessive number of components, similar to an overfitted mixture model, to approximate a Dirichlet process and infer the number of clusters present.\n\nWe use a Gaussian density to model each class/cluster.\n\n\n\n::: {.cell hash='mdir_cache/html/mcmc_e3819f22a1da3c3793d659f82652490b'}\n\n```{.r .cell-code}\nn_chains <- 10\nR <- 10000\nthin <- 50\ntypes <- c(\"G\", \"G\", \"G\")\nK_max <- c(K, 50, 50)\nfixed <- initial_labels <- matrix(0, nrow = N, 3)\n\nfixed[, 1] <- gen_data$fixed\ninitial_labels[, 1] <- gen_data$group_IDs\ninitial_labels[, 2] <- generateInitialUnsupervisedLabels(N, rep(1, K_max[2]), K_max[2])\ninitial_labels[, 3] <- generateInitialUnsupervisedLabels(N, rep(1, K_max[3]), K_max[3])\n\nX <- list(\n  gen_data$observed_data,\n  gen_view_2$gen_data,\n  gen_view_3$gen_data\n)\n\nmcmc_semi <- mdir::runMCMCChains(X, n_chains,\n  R = R,\n  thin = thin,\n  types = types,\n  K = K_max,\n  fixed = fixed,\n  initial_labels = initial_labels\n)\n```\n:::\n\n\n# Processing the MCMC\n\nWe throw away for the first 20% of samples to remove the warm-up bias and construct posterior similarity matrices to show how well the method captured the structure and the uncertainty about this.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nburn <- R * 0.2\nmcmc_semi <- mdir::predictFromMultipleChains(mcmc_semi, burn)\n\npsm_semi_1 <- mcmc_semi$allocations[[1]] |> createSimilarityMat()\nrow.names(psm_semi_1) <- row.names(gen_data$observed_data)\n\npsm_semi_2 <- mcmc_semi$allocations[[2]] |> createSimilarityMat()\nrow.names(psm_semi_2) <- row.names(gen_data$observed_data)\n\npsm_semi_3 <- mcmc_semi$allocations[[3]] |> createSimilarityMat()\nrow.names(psm_semi_3) <- row.names(gen_data$observed_data)\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nannotatedHeatmap(psm_semi_1, gen_data$group_IDs,\n  col_pal = simColPal(),\n  my_breaks = defineBreaks(simColPal(), lb = 0),\n  main = \"PSM - dataset 1\"\n)\n```\n\n::: {.cell-output-display}\n![](mdir_files/figure-html/inspectOutput-1.png){width=672}\n:::\n\n```{.r .cell-code}\nannotatedHeatmap(psm_semi_2, gen_view_2$labels,\n  col_pal = simColPal(),\n  my_breaks = defineBreaks(simColPal(), lb = 0),\n  main = \"PSM - dataset 2\"\n)\n```\n\n::: {.cell-output-display}\n![](mdir_files/figure-html/inspectOutput-2.png){width=672}\n:::\n\n```{.r .cell-code}\nannotatedHeatmap(psm_semi_3, gen_view_3$labels,\n  col_pal = simColPal(),\n  my_breaks = defineBreaks(simColPal(), lb = 0),\n  main = \"PSM - dataset 3\"\n)\n```\n\n::: {.cell-output-display}\n![](mdir_files/figure-html/inspectOutput-3.png){width=672}\n:::\n\n```{.r .cell-code}\nmcmc_semi$pred[[2]] <- mcclust::maxpear(psm_semi_2)$cl\nmcmc_semi$pred[[3]] <- mcclust::maxpear(psm_semi_3)$cl\n```\n:::\n\n\nWe also look at the $\\phi$ vector. In MDI this reflects how much information is shared between each pair of views and is also inferred from the data.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nn_phis <- choose(mcmc_semi$V, 2)\nphi_names <- c()\nfor (v in seq(1, mcmc_semi$V - 1)) {\n  for (u in seq(v + 1, mcmc_semi$V)) {\n    .name <- paste0(\"Phi_\", v, u)\n    phi_names <- c(phi_names, .name)\n  }\n}\n\nphi_df <- mcmc_semi$phis |>\n  data.frame() |>\n  magrittr::set_colnames(phi_names) |>\n  dplyr::mutate(Iteration = rep(seq(mcmc_semi$burn + mcmc_semi$thin, mcmc_semi$R, mcmc_semi$thin), n_chains)) |>\n  tidyr::pivot_longer(-Iteration, values_to = \"Sampled_value\", names_to = \"Parameter\")\n\nphi_df |>\n  ggplot2::ggplot(ggplot2::aes(x = Iteration, y = Sampled_value, colour = Parameter)) +\n  ggplot2::geom_line()\n```\n\n::: {.cell-output-display}\n![](mdir_files/figure-html/phis-1.png){width=672}\n:::\n\n```{.r .cell-code}\nphi_df |>\n  dplyr::filter(Sampled_value < 40) |>\n  ggplot2::ggplot(ggplot2::aes(x = Sampled_value, fill = Parameter)) +\n  ggplot2::geom_density(alpha = 0.3) +\n  ggthemes::scale_fill_colorblind()\n```\n\n::: {.cell-output-display}\n![](mdir_files/figure-html/phis-2.png){width=672}\n:::\n\n```{.r .cell-code}\narandi(gen_data$group_IDs, gen_view_2$labels)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 0.3332854\n```\n:::\n\n```{.r .cell-code}\narandi(gen_data$group_IDs, gen_view_3$labels)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 0.2112762\n```\n:::\n\n```{.r .cell-code}\narandi(gen_view_2$labels, gen_view_3$labels)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 0.07709369\n```\n:::\n:::\n\n\nWe see that $\\phi_{1,2}$ is the largest, showing that the most information is shared between these views, matching higher similarity in the generating structures.\n\nFinally, how well do our point estimates align with the true structure?\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Only use the unobserved labels in the first datset for fair comparison\ntest_inds <- which(fixed[, 1] == 0)\nari_1 <- arandi(mcmc_semi$pred[[1]][test_inds], gen_data$group_IDs[test_inds])\nari_2 <- arandi(mcmc_semi$pred[[2]], gen_view_2$labels)\nari_3 <- arandi(mcmc_semi$pred[[3]], gen_view_3$labels)\n\nari_df <- data.frame(\"Dataset\" = c(1, 2, 3), \"ARI\" = c(ari_1, ari_2, ari_3))\n\nknitr::kable(ari_df, digits = 3)\n```\n\n::: {.cell-output-display}\n| Dataset|   ARI|\n|-------:|-----:|\n|       1| 0.962|\n|       2| 0.345|\n|       3| 0.686|\n:::\n\n```{.r .cell-code}\nround(mcmc_semi$Time, 1)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nTime difference of 26.2 mins\n```\n:::\n:::\n\n\nWe see that in the semi-supervised dataset we uncover the generating structure with great success, but the point estimates in the other datasets are less good. However, the PSMs show that we have uncovered the true clusterings with some success, even if there is high uncertainty about this.\n\nIt takes about 26 minutes to run the ten chains for 10,000 iterations each on the three datasets on the laptop I have built this vignette on.\n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}