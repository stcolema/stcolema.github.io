{
  "hash": "9da8cb094591efb119c62becac82dd30",
  "result": {
    "markdown": "---\ntitle: \"batchmix: Bayesian mixture modelling for multi-batch data\"\neditor: visual\ndata: 2022-08-01\ncategories: [Bayes]\nbibliography: batchmix.bib\n---\n\n\nMy R package, batchmix, finally landed on [CRAN](https://cran.r-project.org/web/packages/batchmix/index.html). This implements the models described in my paper [@Coleman2022BatchModel], mixture models aimed at accounting for batch effects.\n\nThe model is very similar to the COMBAT algorithm of @JohnsonAdjustingbatcheffects2007, but infers batch effects and class at the same time. This makes the method semi-supervised as it uses the inferred labels to update class parameters. This offers some protection from unequal representation of class across batches which is nice. \n\nThis post will essentially recreate the vignette for the package showing how to use it.\n\n\n## Data generation\n\nWe simulate some data using the ``generateBatchData`` function.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(ggplot2)\nlibrary(batchmix)\nlibrary(mdiHelpR)\n```\n\n::: {.cell-output .cell-output-stderr}\n```\n\nAttaching package: 'mdiHelpR'\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\nThe following object is masked from 'package:batchmix':\n\n    createSimilarityMat\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\nThe following object is masked from 'package:methods':\n\n    show\n```\n:::\n\n```{.r .cell-code}\nset.seed(1)\nsetMyTheme()\n\n# Data dimensions\nN <- 600\nP <- 4\nK <- 5\nB <- 7\n\n# Generating model parameters\nmean_dist <- 2.25\nbatch_dist <- 0.3\ngroup_means <- seq(1, K) * mean_dist\nbatch_shift <- rnorm(B, mean = batch_dist, sd = batch_dist)\nstd_dev <- rep(2, K)\nbatch_var <- rep(1.2, B)\ngroup_weights <- rep(1 / K, K)\nbatch_weights <- rep(1 / B, B)\ndfs <- c(5, 10, 15, 20, 80)\n\nmy_data <- generateBatchData(\n  N,\n  P,\n  group_means,\n  std_dev,\n  batch_shift,\n  batch_var,\n  group_weights,\n  batch_weights,\n  type = \"MVT\",\n  group_dfs = dfs\n)\n```\n:::\n\n\nThis gives us a named list with two related datasets, the ``observed_data`` \nwhich includes batch effects and the ``corrected_data`` which is batch-free. It\nalso includes ``group_IDs``, a vector indicating class membership for each item,\n``batch_IDs``, which indicates batch of origin for each item, and ``fixed``,\nwhich indicates which labels are observed and fixed in the model. We pull these \nout of the names list in the format that the modelling functions desire them.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nX <- my_data$observed_data\n\ntrue_labels <- my_data$group_IDs\nfixed <- my_data$fixed\nbatch_vec <- my_data$batch_IDs\n\nalpha <- 1\ninitial_labels <- generateInitialLabels(alpha, K, fixed, true_labels)\n```\n:::\n\n\n## Modelling\n\nGiven some data, we are interested in modelling it. We assume here that the set\nof observed labels includes at least one example of each class in the data. \n\n\n::: {.cell hash='index_cache/html/runMCMCChains_b2206cd32c31a2c97f4dda6f9c94cc86'}\n\n```{.r .cell-code}\n# Sampling parameters\nR <- 1000\nthin <- 50\nn_chains <- 4\n\n# Density choice\ntype <- \"MVT\"\n\n# MCMC samples and BIC vector\nmcmc_output <- runMCMCChains(\n  X,\n  n_chains,\n  R,\n  thin,\n  batch_vec,\n  type,\n  initial_labels = initial_labels,\n  fixed = fixed,\n  batch_specific_weights = TRUE\n)\n```\n:::\n\n\nWe want to assess two things. First, how frequently the proposed parameters in the Metropolis-Hastings step are accepted:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nplotAcceptanceRates(mcmc_output)\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/plotAcceptanceRatesEarly-1.png){width=672}\n:::\n:::\n\n\nSecondly, we want to asses how well our chains have converged. To do this we plot the ``complete_likelihood`` of each chain. This is the quantity most relevant to a clustering/classification, being dependent on the labels. The ``observed_likelihood`` is independent of labels and more relevant for density estimation.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nplotLikelihoods(mcmc_output)\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/likelihood-1.png){width=672}\n:::\n:::\n\n\nWe see that our chains disagree. We have to run them for more iterations. We use the ``continueChains`` function for this.\n\n\n::: {.cell hash='index_cache/html/continueChains_c638ffd941d4e201d4b502d1a732dd6c'}\n\n```{.r .cell-code}\nR_new <- 9000\n\n# Given an initial value for the parameters\nnew_output <- continueChains(\n  mcmc_output,\n  X,\n  fixed,\n  batch_vec,\n  R_new,\n  keep_old_samples = TRUE\n)\n```\n:::\n\n\nTo see if the chains better agree we re-plot the likelihood.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nplotLikelihoods(new_output)\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/continuedLikelihood-1.png){width=672}\n:::\n:::\n\n\nWe also re-check the acceptance rates.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nplotAcceptanceRates(new_output)\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/plotAcceptanceRates-1.png){width=672}\n:::\n:::\n\n\nThis looks like several of the chains agree by the 5,000th iteration.\n\n## Process chains\n\nWe process the chains, acquiring point estimates of different quantities.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Burn in\nburn <- 5000\n\n# Process the MCMC samples\nprocessed_samples <- processMCMCChains(new_output, burn)\n```\n:::\n\n\n## Visualisation\n\nFor multidimensional data we use a PCA plot.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nchain_used <- processed_samples[[1]]\n\npc <- prcomp(X, scale = T)\npc_batch_corrected <- prcomp(chain_used$inferred_dataset)\n\nplot_df <- data.frame(\n  PC1 = pc$x[, 1],\n  PC2 = pc$x[, 2],\n  PC1_bf = pc_batch_corrected$x[, 1],\n  PC2_bf = pc_batch_corrected$x[, 2],\n  pred_labels = factor(chain_used$pred),\n  true_labels = factor(true_labels),\n  prob = chain_used$prob,\n  batch = factor(batch_vec)\n)\n\nplot_df |> \n  ggplot(aes(\n    x = PC1,\n    y = PC2,\n    colour = true_labels,\n    alpha = prob\n  )) +\n  geom_point()\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/pca-1.png){width=672}\n:::\n\n```{.r .cell-code}\nplot_df |> \n  ggplot(aes(\n    x = PC1_bf,\n    y = PC2_bf,\n    colour = pred_labels,\n    alpha = prob\n  )) +\n  geom_point()\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/pca-2.png){width=672}\n:::\n\n```{.r .cell-code}\ntest_inds <- which(fixed == 0)\n\nsum(true_labels[test_inds] == chain_used$pred[test_inds])/length(test_inds)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 0.7212766\n```\n:::\n:::\n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}